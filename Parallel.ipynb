{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Found 666 images belonging to 2 classes.\n",
      "Found 666 images belonging to 2 classes.\n",
      "Found 666 images belonging to 2 classes.\n",
      "61/62 [============================>.] - ETA: 0s - loss: 7.1725 - acc: 0.5441Found 334 images belonging to 2 classes.\n",
      "Found 334 images belonging to 2 classes.\n",
      "Found 334 images belonging to 2 classes.\n",
      "62/62 [==============================] - 31s 503ms/step - loss: 7.1868 - acc: 0.5434 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 26s 414ms/step - loss: 8.0671 - acc: 0.4995 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 26s 420ms/step - loss: 4.3419 - acc: 0.5418 - val_loss: 0.7443 - val_acc: 0.6296\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 26s 415ms/step - loss: 0.7061 - acc: 0.5753 - val_loss: 1.2719 - val_acc: 0.6280\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 26s 412ms/step - loss: 0.6136 - acc: 0.6737 - val_loss: 6.0775 - val_acc: 0.6113\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 26s 414ms/step - loss: 0.7128 - acc: 0.7919 - val_loss: 1.8690 - val_acc: 0.5955\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 26s 413ms/step - loss: 0.7188 - acc: 0.8136 - val_loss: 5.9496 - val_acc: 0.5789\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 26s 412ms/step - loss: 0.7777 - acc: 0.8576 - val_loss: 2.1565 - val_acc: 0.5630\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 25s 409ms/step - loss: 0.9792 - acc: 0.8287 - val_loss: 4.7414 - val_acc: 0.5466\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 25s 411ms/step - loss: 0.9354 - acc: 0.8629 - val_loss: 6.6164 - val_acc: 0.5305\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 26s 413ms/step - loss: 1.1825 - acc: 0.8725 - val_loss: 3.9689 - val_acc: 0.5142\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 25s 410ms/step - loss: 0.5502 - acc: 0.8936 - val_loss: 2.0765 - val_acc: 0.4980\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 26s 412ms/step - loss: 0.8538 - acc: 0.8931 - val_loss: 5.2340 - val_acc: 0.4818\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 25s 408ms/step - loss: 0.7487 - acc: 0.8901 - val_loss: 2.8152 - val_acc: 0.4654\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 26s 415ms/step - loss: 0.9008 - acc: 0.8810 - val_loss: 1.9834 - val_acc: 0.4494\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 25s 411ms/step - loss: 0.7318 - acc: 0.8326 - val_loss: 0.7010 - val_acc: 0.4289\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 25s 404ms/step - loss: 0.7834 - acc: 0.8377 - val_loss: 1.3228 - val_acc: 0.4170\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 25s 408ms/step - loss: 0.7267 - acc: 0.8079 - val_loss: 3.3245 - val_acc: 0.4004\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 25s 408ms/step - loss: 0.9286 - acc: 0.8785 - val_loss: 0.6784 - val_acc: 0.6123\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 25s 408ms/step - loss: 0.8478 - acc: 0.4848 - val_loss: 0.7174 - val_acc: 0.3659\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 25s 410ms/step - loss: 0.7044 - acc: 0.8155 - val_loss: 0.6698 - val_acc: 0.6478\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 26s 412ms/step - loss: 0.4755 - acc: 0.7903 - val_loss: 3.9590 - val_acc: 0.6619\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 26s 415ms/step - loss: 0.7772 - acc: 0.7449 - val_loss: 0.6623 - val_acc: 0.6606\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 26s 415ms/step - loss: 0.6385 - acc: 0.5952 - val_loss: 2.1219 - val_acc: 0.6437\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 26s 421ms/step - loss: 0.6429 - acc: 0.7590 - val_loss: 5.3279 - val_acc: 0.6280\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 26s 414ms/step - loss: 0.9535 - acc: 0.8246 - val_loss: 6.2153 - val_acc: 0.6113\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 26s 413ms/step - loss: 0.6826 - acc: 0.8694 - val_loss: 1.6035 - val_acc: 0.5955\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 25s 410ms/step - loss: 0.4707 - acc: 0.8720 - val_loss: 4.3490 - val_acc: 0.5789\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 25s 407ms/step - loss: 0.6219 - acc: 0.8507 - val_loss: 1.8606 - val_acc: 0.5630\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 25s 410ms/step - loss: 0.5969 - acc: 0.8115 - val_loss: 4.5133 - val_acc: 0.5466\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 26s 412ms/step - loss: 0.6078 - acc: 0.8523 - val_loss: 1.8152 - val_acc: 0.5305\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 25s 411ms/step - loss: 0.4592 - acc: 0.8795 - val_loss: 3.7622 - val_acc: 0.5142\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 25s 411ms/step - loss: 0.8393 - acc: 0.8306 - val_loss: 0.7075 - val_acc: 0.4980\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 25s 404ms/step - loss: 0.6171 - acc: 0.7610 - val_loss: 1.4580 - val_acc: 0.4818\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 26s 414ms/step - loss: 0.6308 - acc: 0.8009 - val_loss: 1.4097 - val_acc: 0.4654\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 25s 410ms/step - loss: 0.7011 - acc: 0.8553 - val_loss: 2.7745 - val_acc: 0.4494\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 25s 408ms/step - loss: 0.5600 - acc: 0.8674 - val_loss: 4.3164 - val_acc: 0.4329\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 25s 406ms/step - loss: 0.5280 - acc: 0.8951 - val_loss: 3.7193 - val_acc: 0.4170\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 25s 408ms/step - loss: 0.5271 - acc: 0.9138 - val_loss: 0.7495 - val_acc: 0.3963\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 25s 407ms/step - loss: 0.6069 - acc: 0.8881 - val_loss: 0.7446 - val_acc: 0.4231\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 25s 407ms/step - loss: 0.5755 - acc: 0.8347 - val_loss: 1.0910 - val_acc: 0.5071\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 25s 405ms/step - loss: 0.3742 - acc: 0.9294 - val_loss: 4.2031 - val_acc: 0.6478\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 26s 414ms/step - loss: 0.6557 - acc: 0.7938 - val_loss: 3.9482 - val_acc: 0.6619\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 25s 411ms/step - loss: 0.5038 - acc: 0.8977 - val_loss: 4.1734 - val_acc: 0.6606\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 25s 410ms/step - loss: 0.6879 - acc: 0.8160 - val_loss: 3.3982 - val_acc: 0.6437\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 25s 409ms/step - loss: 0.5904 - acc: 0.9057 - val_loss: 0.9484 - val_acc: 0.6280\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 25s 411ms/step - loss: 0.5197 - acc: 0.8593 - val_loss: 5.8592 - val_acc: 0.6113\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 26s 411ms/step - loss: 0.4648 - acc: 0.9093 - val_loss: 4.6289 - val_acc: 0.5955\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 26s 413ms/step - loss: 0.6190 - acc: 0.8634 - val_loss: 5.7169 - val_acc: 0.5789\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 26s 411ms/step - loss: 0.7070 - acc: 0.8952 - val_loss: 5.1656 - val_acc: 0.5630\n",
      "Estimated time: 1280.6295356750488 s\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "    # dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train1_data_dir = 'data/train1'\n",
    "train2_data_dir = 'data/train2'\n",
    "train3_data_dir = 'data/train3'\n",
    "val1_data_dir = 'data/val1'\n",
    "val2_data_dir = 'data/val2'\n",
    "val3_data_dir = 'data/val3'\n",
    "nb_train_samples = 999\n",
    "nb_validation_samples = 501\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "'''\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mergedOut = Add()([model1.output,model2.output,model3.output])\n",
    "\n",
    "mergedOut = Flatten()(mergedOut)    \n",
    "mergedOut = Dense(64, activation='relu')(mergedOut)\n",
    "mergedOut = Dropout(.5)(mergedOut)\n",
    "mergedOut = Dense(2, activation='sigmoid')(mergedOut)\n",
    "\n",
    "model = Model([model1.input,model2.input,model3.input], mergedOut)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "def generate_generator_multiple(generator,dir1, dir2, dir3, batch_size, img_height,img_width):\n",
    "    genX1 = generator.flow_from_directory(dir1,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          seed=7)\n",
    "    \n",
    "    genX2 = generator.flow_from_directory(dir2,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          seed=7)\n",
    "    \n",
    "    genX3 = generator.flow_from_directory(dir3,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          seed=7)\n",
    "    \n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            X3i = genX3.next()\n",
    "            yield [X1i[0], X2i[0], X3i[0]], X3i[1]  #Yield both images and their mutual label\n",
    "            \n",
    "            \n",
    "train_generator=generate_generator_multiple(generator=train_datagen,\n",
    "                                           dir1=train1_data_dir,\n",
    "                                           dir2=train2_data_dir,\n",
    "                                           dir3=train3_data_dir,\n",
    "                                           batch_size=batch_size,\n",
    "                                           img_height=img_height,\n",
    "                                           img_width=img_height)       \n",
    "\n",
    "\n",
    "validation_generator=generate_generator_multiple(generator=test_datagen,\n",
    "                                          dir1=val1_data_dir,\n",
    "                                          dir2=val2_data_dir,\n",
    "                                          dir3=val3_data_dir,\n",
    "                                          batch_size=batch_size,\n",
    "                                          img_height=img_height,\n",
    "                                          img_width=img_height) \n",
    "\n",
    "'''\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save('para_try.h5')\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "    \n",
    "print(\"Estimated time:\",total,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
